{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffd3888",
   "metadata": {},
   "source": [
    "<img src=\"img/logo.png\" alt=\"fst\" style=\"width:200px;height:220px;margin-left:0px;\"></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca255ac",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;font-family:serif;font-size:3em;margin:180px\">Application de la \n",
    "recherche par le contenu d’images sur la base de MNIST<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1dffe7",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"margin-left:30px;font-family:serif;font-size:1.4em;\"><strong>Module:</strong>Base de données multimédias</div>\n",
    "<div style=\"font-size:1.4em;margin:30px;font-family:serif;\"><strong>Filière :</strong>Informatique, Réseau et multimédias \n",
    "\n",
    "</div>\n",
    "<div style=\"font-family:serif;font-size:1.4em;margin:30px\"><strong>Année universitaire: \n",
    "    </strong>2023/2022</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2a342",
   "metadata": {},
   "source": [
    "<div style=\";font-family:serif;font-size:1.5em;display:flex;\">\n",
    "<div>\n",
    "\n",
    "\n",
    "<p style=\";font-family:serif;font-size:1.5em;margin:30px\">Professeur encadrant </p>\n",
    "<p style=\";font-family:serif;margin-left:40px\">Mohammed KHALIL</p>\n",
    "</div>\n",
    "<div style=\"margin-left:300px\">\n",
    "<p style=\";font-family:serif;font-size:1.5em;margin:30px\">Réaliser par </p>\n",
    "<ul>\n",
    " <li style=\"margin:10px\">Rachid BENHSINA</li> \n",
    "<li style=\"margin:10px\">Saifedinne DOUIDY</li> \n",
    "    <li style=\"margin:10px\">Souhaib GARAAOUCH</li> \n",
    "    <li style=\"margin:10px\">Abdelkebir BOUCHTI</li> \n",
    "    \n",
    "  \n",
    "</ul>\n",
    "</div>\n",
    "   </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f93d0d",
   "metadata": {},
   "source": [
    "<hr style=\"color:black;width:100% ;height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d713cb",
   "metadata": {},
   "source": [
    "<h1 class=\"title\" style=\"text-align: center;font-family:serif;font-size:4em\">Table de matières</h1>\n",
    "   \n",
    "<h2 class=\"ch\" style=\"font-weight: bold;font-family:serif;font-size:2.6em;margin:40px\" >Chapitre 1: <span>Introduction</span></h2>\n",
    "    <ol>\n",
    "        <li style=\"font-family:serif;font-size:2em;margin:10px;margin:20px\">Introduction générale</li>\n",
    "        <li style=\"font-family:serif;font-size:2em;margin:10px;margin:20px\">Historique sur la CIBR</li>\n",
    "        <li style=\"font-family:serif;font-size:2em;margin:10px;margin:20px\">Présentation de la base de données de MNIST</li>\n",
    "        <li style=\"font-family:serif;font-size:2em;margin:10px;margin:20px\"> L'architecture des systèmes d'indexation et de recherche d’images</li>\n",
    "    </ol>\n",
    "    <h2 class=\"ch\" style=\"font-weight: bold;font-family:serif;font-size:2.6em;margin:40px\">Chapitre 2: <span>Implementation du système d’indexation</span></h2>\n",
    "    <ol>\n",
    "        <li style=\"font-family:serif;font-size:2em;margin:10px;margin:20px\">présentation de la problématique</li>\n",
    "        <li style=\"font-family:serif;font-size:2em;margin:10px;margin:20px\">Descripteur utilisé </li>\n",
    "        <li style=\"font-family:serif;font-size:2em;margin:10px;margin:20px\"> Implémentation du code</li>\n",
    "    </ol>\n",
    "    <h2 class=\"ch\" style=\"font-weight: bold;font-family:serif;font-size:2.6em;margin:40px\">Chapitre 3: <span>Evaluation et mesure de performance </span></h2>\n",
    "    <ol>\n",
    "        <li style=\"font-family:serif;font-size:2em;margin:10px;margin:20px\">Rappel et précision</li>\n",
    "        <li style=\"font-family:serif;font-size:2em;margin:10px;margin:20px\">Courbe CMC</li>\n",
    "    </ol>\n",
    "    <h2 class=\"ch\" style=\"font-weight: bold;font-family:serif;font-size:2.6em;margin:40px\">Chapitre 4: <span>Résumer </span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f7381e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2136f507",
   "metadata": {},
   "source": [
    "<hr style=\"color:black;width:100% ;height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7480a842",
   "metadata": {},
   "source": [
    "<div style=\"width:500px;margin-left:200px;margin-right:200px;font-size:1.3em;margin:100px;font-size:1.4em\"><strong>Abstract:</strong><br><br>\n",
    " In this study, we developed a content-based image retrieval system using the MNIST database. This system was designed to respond to requests for retrieving similar images based on their visual content rather than metadata such as tags or captions. We used the Histogram of Oriented Gradients (HOG) descriptor to represent the visual content of the images, and a distance matrix to measure the similarity between images. The system was trained with 800 images and tested with 200 images, and the average accuracy was calculated to evaluate its performance in retrieving similar images. The results show that our system is effective in retrieving similar images based on their visual content, demonstrating the potential of using the HOG descriptor and distance matrix for the task of content-based image retrieval. Future work could include optimizing the similarity measurement method and extending the system to larger databases.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d466291",
   "metadata": {},
   "source": [
    "<div style=\"margin:100px;font-size:1.3em;\"><strong>Keywords:</strong> Indexation d’images ,Distance de similarité,recherche par centenue,MNIST</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a4f8ca",
   "metadata": {},
   "source": [
    "<hr style=\"color:black;width:100% ;height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441a772d",
   "metadata": {},
   "source": [
    "<h2 class=\"ch\" style=\"font-weight: bold;font-family:serif\">Chapitre 1: <span>Introduction</span></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ab5e01",
   "metadata": {},
   "source": [
    "<div ><strong>1.1)Introducion generale:</strong></div>\n",
    "\n",
    "\n",
    "L’une des conséquences directes de la baisse des coûts des équipements informatiques, du développement des télécommunications et de la disponibilité des techniques de numérisation de haute qualité, est la création et l’échange de volumes de plus en plus importants de données multimédias numérisées. Ces données sont par essence hétérogènes et leur contenu prépondérant est visuel.\n",
    "\n",
    "\n",
    "Les développements récents dans les domaines du traitement d'image et des bases de données offrent tous les éléments nécessaires pour l’extraction, l’indexation et la recherche du contenu visuel des données multimédias, notamment les images.\n",
    "\n",
    "\n",
    "La mise en œuvre de l’indexation et de la recherche dans un contexte de très grande collection d’images fait appel à des techniques développées dans deux domaines différents : l'analyse d’images et les bases de données. Cette mise en œuvre s’effectue dans le cadre d’un Système de Recherche d’Images par le Contenu (SRIC ou CBIR pour Content Based Image Retrieval), qui consiste à chercher des images similaires à une image requête en se basant sur le contenue visuel des images comme: la couleur, la texture et la forme ou toute autre information pouvant être dérivée de l'image elle-même.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45eafd2",
   "metadata": {},
   "source": [
    "<strong>I.2)Historique de la CIBR</strong>\n",
    "\n",
    "\n",
    "Le terme \"recherche d'images par contenue\" semble avoir vu le jour en 1992 lorsqu'il a été utilisé par l' ingénieur du \n",
    "laboratoire électrotechnique japonais Toshikazu Kato pour décrire des expériences de récupération automatique d'images à partir d'une base de données, en fonction des couleurs et des formes présentes.\n",
    "\n",
    "\n",
    "\n",
    "Depuis lors, le terme a été utilisé pour décrire le processus de récupération des images souhaitées à partir d'une grande collection sur la base des caractéristiques synthétique  de l'image. \n",
    "Les techniques,outils et algorithmes utilisés proviennent de domaines tels que les statistiques, la reconnaissance de formes, le traitement d'image et la vision par ordinateur.\n",
    "\n",
    "\n",
    "Le premier système CBIR commercial a été développé par IBM et s'appelait QBIC ( Query By Image Content )  en français c’est Requête par contenu d'image.\n",
    "Le CIBR s’oppose au recherche d’image par  les métadonnées (l'indexation manuelle) telles que les mots-clés ou les descriptions associées à l'image.\n",
    "    \n",
    "En fait, faire annoter manuellement les images par des humains en saisissant des mots-clés ou des métadonnées dans une grande base de données peut prendre du temps et peut ne pas capturer les mots-clés souhaités pour décrire exactement le contenue de l'image.\n",
    "\n",
    "\n",
    "L'évaluation de l'efficacité de l'indexation textuelle des images est subjective et n'a pas été bien définie. Dans le même ordre d'idées, les systèmes CBIR ont des défis similaires pour définir le succès, même  si Les reponse au requête sont approximatives et n’ont pas exactes c’est pas comme le cas d’une recherche   par des métadonnées qui donne des images qui vérifie exactement le critère d’interrogation mais ce n'est pas suffisant pour garantir la pertinence du résultat obtenue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eb864a",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebd977",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:serif\">1.3)la base de donne de MNIST:</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85c97d",
   "metadata": {},
   "source": [
    "\n",
    "Le jeu de données qu'on va l'utilisé  dans ce mini-projat c'est Le jeu de données\n",
    "MNIST (Modified National Institute of Standards and Technology) ,c'est une base de données de chiffres manuscrits utilisée pour l'apprentissage en machine et la reconnaissance optique de caractères. Elle a été créée en 1998 par Yann LeCun, Corinna Cortes et Christopher J.C. Burges, tous trois chercheurs chez AT&T Bell Labs à l'époque. La base de données MNIST comprend 70 000 images de chiffres manuscrits au niveau de gris, avec une taille de 28x28 pixels chacune. Les images sont divisées en deux ensembles : un ensemble d'apprentissage de 60 000 images et un ensemble de test de 10 000 images. Cette base de données est devenue une référence  pour l'évaluation des algorithmes de reconnaissance de caractères manuscrits et a été utilisée dans de nombreuses applications, notamment la reconnaissance de codes postaux, la reconnaissance de chèques bancaires et la reconnaissance de plaques d'immatriculation.\n",
    "\n",
    "\n",
    "MNIST est issue d'un mélange des bases SD-1 (Special Database 1) et SD-3 (Special Database 3) du NIST qui contiennent des chiffres écrits respectivement par des lycéens et des employés du United States Census Bureau. Les images sources, sélectionnées par Chris Burges et Corinna Cortes, ont été initialement codées dans des matrices 20 x 20, puis converties en matrices de 28 lignes par 28 colonnes, chaque composante de la matrice étant codée sur un octet .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9773dd",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:serif\">I.4)Architecture d'un système CBIR:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399d149",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553ae47",
   "metadata": {},
   "source": [
    "\n",
    "Dans cette section, nous présentons l’architecture du système de recherche d’images par le contenu. Nous présentons aussi la façon que ce système utilise pour prendre la (les) requête(s), calculer la distance et lancer des résultats. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf6ceeb",
   "metadata": {},
   "source": [
    "Chaque  système  de CIBR s’exécute en deux étapes : l’étape d’indexation et l’étape de recherche.\n",
    "\n",
    "<li><strong>La phase d’indexation (hors-Ligne) :</strong></li>\n",
    "Dans cette phase, des\n",
    "caractéristiques sont automatiquement extraites pour chaque image et\n",
    "stockées dans un vecteur numérique appelé descripteur visuel pour former la base des descripteurs .\n",
    "Grâce aux techniques de la base de données, on peut stocker ces caractéristiques\n",
    "et les récupérer rapidement et efficacement. \n",
    "<li><strong>La phase recherche (On-line) :</strong></li>\n",
    " Dans cette étape, le système analyse une\n",
    " requête émises par l’utilisateur et lui donne le résultat\n",
    "correspond en une liste d’images ordonnées, en fonction de la similarité\n",
    "entre les descripteur qui sont déjà stockées  et celui de l’image requête en utilisant une\n",
    "métrique de distance. \n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d4a68",
   "metadata": {},
   "source": [
    "La figure <strong>Fig.1-1</strong> ci-dessous schématise la structure d'une système CBIR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35c7516",
   "metadata": {},
   "source": [
    "<img src=\"img/archetectur.PNG\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095bc8ce",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><strong>Fig. 1-1:</strong> L’architecture d’un système d’indexation et recherche d’images \n",
    "par le contenu</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a03c1a",
   "metadata": {},
   "source": [
    "Les performances des systèmes de recherche dépend pour une grande partie du choix des \n",
    "descripteurs employés et des techniques associées à leur extraction. De nombreux descripteurs \n",
    "sont utilisés dans les systèmes de recherche pour décrire les images. Ceux-ci peuvent être \n",
    "différenciés selon deux niveaux : \n",
    "Les descripteurs de bas niveau : les plus utilisés dans les systèmes actuels sont la couleur, la \n",
    "texture et la forme, leur pouvoir de discrimination étant limité au contenu visuel de l’image. \n",
    "Les descripteurs de haut niveau : tendent à se rapprocher du contenu sémantique de l’image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead79a2",
   "metadata": {},
   "source": [
    "<h2 class=\"ch\" style=\"font-weight: bold;font-family:serif;font-size:2em\">Chapitre 2: <span>Implementation du système d’indexation</span></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307aeb7e",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:serif\">II.1)présentation de la problématique:</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b900594",
   "metadata": {},
   "source": [
    "Ce mini-projet consiste à créer un système de recherche par contenu appliqué sur une partie de la base de données MNIST. L'ensemble d'entraînement contient 800 images, chaque classe étant représentée par les 80 images premières du même class de l'ensemble d'entraînement de MNIST. L'ensemble de test est composé de 200 images, soit 20 images par classe qui sont  les 20 premières du même classe dans la partie de test de la base de données d'origine MNIST. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1938f",
   "metadata": {},
   "source": [
    "Le défi consiste à concevoir un système de recherche qu'fait une classification multi-class.\n",
    "\n",
    "Pour un images requête donnée qui peut être l'une des 10 class (de 0 à 9),\n",
    "La réponse que doit fournir le système c'est la récupération des k images de même class. une image considérer comme une image pertinente s’il   appartient au même class (c'est à dire contient le même chiffre manuscrit).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b6581",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:serif\">II.1)Analyse de la problématique:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9176621",
   "metadata": {},
   "source": [
    "Avant d'entamer le codage, il convient de se plonger légèrement dans les détails pour déterminer quel descripteur serait adapté à notre situation et quelle métrique l'accompagnerait."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9aca0",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:serif;color:#023300\">Les descripeturs:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f100f63",
   "metadata": {},
   "source": [
    "L’étape clé consiste à choisir un descripteur approprié pour comparer les caractéristiques visuelles de deux images. Cette décision a un impact significatif sur la précision du système de recherche d'images. Pour prendre une décision éclairée, une analyse est nécessaire pour déterminer le type de descripteur qui conviendrait le mieux. Il existe trois types de descripteurs  de bas niveau couramment utilisés dans la littérature :   la couleur, la texture et la forme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a7b806",
   "metadata": {},
   "source": [
    "<li><strong>la couler:</strong>\n",
    "    \n",
    "La couleur est très souvent le premier descripteur qui est employé pour la recherche d’images et  qui donne \n",
    "une information important sur la perception humain , mais dans notre cas malheureusement c'est n'est pas utilisé puisque deux images appartient à deux class différents pouvant avoir des valeurs proches pour la couleur moyenne de même pour l'histogramme de couleur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56af3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BDM import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import*\n",
    "from tqdm import *\n",
    "\n",
    "Train_set_totale= pd.read_csv('mnist_train.csv')\n",
    "Train_set_totale=np.array(Train_set_totale.iloc[::])\n",
    "Train_set =load_img(Train_set_totale,80,28)\n",
    "img1=Train_set[:,:,0]\n",
    "img2=Train_set[:,:,50]\n",
    "img3=Train_set[:,:,505]\n",
    "print(\"la coleur moyenne des image\")\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img1,'gray') \n",
    "plt.xlabel(couleur_moyenne(img1))\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img3,'gray') \n",
    "plt.xlabel(couleur_moyenne(img3))\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(img2,'gray') \n",
    "plt.xlabel(couleur_moyenne(img2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e4a6a",
   "metadata": {},
   "source": [
    "Ce n'est pas une cas particulier mais c'est ce qu'on a remarqué lors de la comparaison entre plusieurs images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08051481",
   "metadata": {},
   "source": [
    "La même chose avec l’histogramme, on peut avoir deux chiffres diffèrent mes possède la même distribution \n",
    "des intensités ce qui ne permet pas de faire la distinction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo1=histo(img1)\n",
    "histo2=histo(img2)\n",
    "histo3=histo(img3)\n",
    "print(\"la distance auclidien entre les histogramme des image de meme class :\",Euclidien(histo1,histo2))\n",
    "print(\"la distance auclidien entre les histogramme des image de different class:\",Euclidien(histo1,histo3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765fde1",
   "metadata": {},
   "source": [
    "La distance entre les images de deux class différente est supérieur à la distance des deux images de la même class.\n",
    "\n",
    "**Noter bien** qu'on a vérifié ça pour plusieurs images pour respecter une règle « l'exception ne fait pas la règle »\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b511e1d",
   "metadata": {},
   "source": [
    "On constat donc que dans ce cas la couleur n'est pas une caractéristique pertinente pour faire la classification  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56036a7a",
   "metadata": {},
   "source": [
    "<li><strong>la Texture:</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bca8fe",
   "metadata": {},
   "source": [
    "L’analyse de texture consiste à calculer une série de mesures dans le but de définir une texture perçue sur une image. L'analyse de texture renvoie des informations sur l'arrangement spatial des couleurs ou des intensités dans tout ou partie de cette image.\n",
    "Mais le problème rencontré ici c’est qu’on peut écrire le même chiffre avec diffèrent dégradation d’intensité.\n",
    "Ce qui pose une diversité au moment de la comparaison entre les mêmes chiffres qui ne possède pas même distribution des intensités.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2beb7a",
   "metadata": {},
   "source": [
    "<li><strong>la form:</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf65bd6",
   "metadata": {},
   "source": [
    "Un descripteur de forme est  une caractéristique utilisée pour décrire la forme d'un objet d'une image . Ces descripteurs peuvent inclure des mesures telles que la surface, la courbure, la longueur du contour, le nombre de coins, la symétrie, la compacité, etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7602b866",
   "metadata": {},
   "source": [
    "Dans notre base de données, chaque image contient uniquement un chiffre. Cependant, les chiffres qui appartiennent à la même classe partagent des caractéristiques de forme similaires, qui déterminent leur apparence visuelle. Ainsi, pour distinguer deux  chiffres, nous pouvons nous baser sur ces caractéristiques de forme pour la mesure de similarite entre les images.\n",
    "\n",
    "Bien que les images de chiffres écrits à la main puissent varier en apparence, il existe néanmoins des règles générales pour l'écriture de chaque chiffre, ce qui signifie que la forme d'un 0 par exemple  diffère de celle d'un 1. Même si les images sont écrites à la main  et peuvent varier, ces règles permettent de différencier les chiffres les uns des autres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6508dcd0",
   "metadata": {},
   "source": [
    "Le choix de l'élément clé dans notre étude est particulièrement important, et nous avons opté pour l'un des descripteurs de forme les plus puissants qui est largement utilisé dans la reconnaissance d'objets: HOG (Histogramme des Orientations de Gradients) qu'on va le détailler dans la section suivant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c9186",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:serif;color:#023300\">Descripetur HOG</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c5c2b",
   "metadata": {},
   "source": [
    "Le HOG (Histogram of Oriented Gradients) a été proposé par Navneet Dalal et Bill Triggs, \n",
    "chercheurs à l'INRIA (Institut national de recherche en informatique et en automatique) de Grenoble, à la conférence CVPR (Conference on Computer Vision and Pattern Recognition) de juin 2005."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5645a144",
   "metadata": {},
   "source": [
    "C’est un descripteur qui calcule l'histogramme des gradients d'intensité de l'image comme son nom l'indique. Il est utiliser pour  la détection d'objets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b470da51",
   "metadata": {},
   "source": [
    "Dans cette section on va expliquer en détail le fonctionnement du HOG pour l’appliquer sur MNIST. \n",
    "Le calcul du descripteur HOG d'une image se fait en cinq étapes :\n",
    "\n",
    "\n",
    "<strong>L'étape 1:Calcul du gradient de l'image   </strong> \n",
    "\n",
    "Le gradient d'une permet de detecter le conteur de l'image. Il s'agit d'un vecteur ∇I\n",
    " composé des dérivées partielles de la fonction d'intensité, et calculé en chaque pixel : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a93a73",
   "metadata": {},
   "source": [
    "<img src=\"img/1.PNG\" style=\"width:240px;height:110px;margin-left:0px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49797dfd",
   "metadata": {},
   "source": [
    "Les dérivées partielles sont définies formellement comme des limites de taux d'accroissement :\n",
    "<img src=\"img/2.PNG\" style=\"width:240px;height:110px;margin-left:0px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf48f6c",
   "metadata": {},
   "source": [
    "La dérivée partielle par rapport à x\n",
    " (ou y\n",
    ") permet d'étudier les variations d'intensités de l'image dans la direction de l'axe des abscisses (ou des ordonnées).\n",
    "\n",
    "À  cause de la discontinuité de l'image la formule pour le calculer du dérivé en un point donné de l’image a été approximer par une formule discrète qui s'adapte bien avec la nature d'image numérique.\n",
    "<img src=\"img/3.PNG\" style=\"width:270px;height:120px;margin-left:0px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f2b61a",
   "metadata": {},
   "source": [
    "Les gardiens Gx et Gy sont calculés en filtrant respectivement l'image par le noyau dégradé horizontal et le noyau dégradé vertical via une opération de convolution.\n",
    "<img src=\"img/0.PNG\" style=\"width:270px;height:120px;margin-left:0px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e3a5ff",
   "metadata": {},
   "source": [
    "À la fin de cette étape, on obtiendra deux matrices Gx et Gy de même taille que l'image d'origine qui représentent respectivement les gradients le long de l'axe x et  les gradients le long de l'axe y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063bffd",
   "metadata": {},
   "source": [
    "<strong>L'étape 2:Calcul des magnitudes et des orientations des gradients  </strong> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847fce83",
   "metadata": {},
   "source": [
    "En utilisant les gradients que nous avons calculés dans   l'étape précèdent, nous allons maintenant calculer la magnitude et la direction de chaque valeur de pixel. Pour cette étape, nous utiliserons le théorème de Pythagore ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6577ff",
   "metadata": {},
   "source": [
    "<img src=\"img/6.PNG\" style=\"width:350px;height:200px;margin-left:0px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a882d",
   "metadata": {},
   "source": [
    "Appliquons le théorème de Pythagore pour calculer l'amplitude totale du gradient :\n",
    "\n",
    "Amplitude totale du gradient = √[(G x )^2 +(G y )^2 ]|\n",
    "Cette formule permet d'identifions si le pixel est un bord ou non, les bords vont avoir des grandes valeurs et les petites valeurs vont affecter au pont qui ne dispose pas un changement brusque d'intensité car il y a pas de variation.\n",
    "\n",
    "Et on sait qu'on peut écrire le tangent de l'angle Φ à l'aide du triangle ci-dessus:\n",
    "\n",
    "tan(Φ) = Gy / Gx\n",
    "\n",
    "La valeur de l'angle serait donc :\n",
    "Φ = arctan(Gy / Gx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bbb7c",
   "metadata": {},
   "source": [
    "À ce stade on a pour chaque pixel de l'image d'origine deux informations : la magnitude du gradient total et l’orientation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30df0e3",
   "metadata": {},
   "source": [
    "<strong>L'étape 3: la  Création des cellules </strong> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6489e5",
   "metadata": {},
   "source": [
    "Après avoir obtenu le gradient de chaque pixel, les matrices de gradient (magnitude et matrice d'angle) sont divisées en 8x8 cellules pour former un bloc. Pour chaque bloc, L'orientation est ensuite normalisée à une plage de 0 à 180 degrés (ou à 0 à 360 degrés, selon la convention choisie). Cette plage est divisée en plusieurs bins, par exemple 9 bins pour une plage de 0 à 180 degrés. Chaque orientation est alors ajoutée au bin correspondant, pondérée par la magnitude du gradient.\n",
    "(sont les parametre adopte dans le mini-projet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32ad49a",
   "metadata": {},
   "source": [
    "Voici un exemple d'histogramme d'un bloc pour un nombre de bins entre  1 et  180."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff69aa8",
   "metadata": {},
   "source": [
    "<img src=\"img/9.PNG\" style=\"width:950px;height:70px;margin-left:0px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d52b600",
   "metadata": {},
   "source": [
    "<strong>L'étape 4:Normalisation de blocs </strong> \n",
    "\n",
    "les valeurs de gradient peuvent varier en fonction de l'éclairage et du contraste du premier plan et de l'arrière-plan.\n",
    "Donc, pour eviter ce problème, nous pouvons normaliser les cellules. Dans de tels cas, la normalisation de bloc a tendance à être plus performante que la normalisation unicellulaire .\n",
    "c'est pour cela on va  regrouper quelques cellules et normaliser les valeurs de gradient de chaque bloc ( cellule groupée ).\n",
    "Le paramètre cells_per_block de la fonction hog dans skimage qui indique le nombre de bloques  utilisées  pour la normalisation.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0df434",
   "metadata": {},
   "source": [
    "nous allons combiner quatre cellules 8 × 8 pour créer un bloc 16 × 16. Et nous savons déjà que chaque cellule 8×8 a une matrice 9×1 pour un histogramme. Ainsi, nous aurions quatre matrices 9 × 1 ou une seule matrice 36 × 1. Pour normaliser cette matrice, nous diviserons chacune de ces valeurs par la racine carrée de la somme des carrés des valeurs. Mathématiquement, pour un vecteur V donné :\n",
    "\n",
    "V = [a1, a2, a3, ….a36]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10d105",
   "metadata": {},
   "source": [
    "On calcule la racine de la somme des carrés :\n",
    "k = √(a1)2+ (a2)2+ (a3)2+ …. (a36)2\n",
    "\n",
    "puis on divise toutes les valeurs du vecteur V par cette valeur k :\n",
    "<img src=\"img/10.PNG\" style=\"width:300px;height:100px;margin-left:0px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6991c764",
   "metadata": {},
   "source": [
    "<strong>L'étape 5:Création du vecteur HOG  </strong>\n",
    "La dernière étape consiste à obtenir le vecteur des caractéristiques HOG.\n",
    "Après avoir calculé toutes les normalisations des blocs, nous les concaténons en un seul vecteur pour obtenir le vecteur de caractéristiques final. Il existe N_vect vecteurs horizontaux et M_vect vecteurs verticaux. Ils s'élèvent à un total de \n",
    "N_vect ×M_vect vecteurs qui sont concaténés pour obtenir le vecteur de caractéristiques final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b989f75",
   "metadata": {},
   "source": [
    "<h3 id=\"9\" style=\"font-family:serif\">II.3)L'implémentation du code en Python:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d1e8a",
   "metadata": {},
   "source": [
    "Toutes les fonction développées sont regrouper dans un fichier port le nom BDM.py .\n",
    "\n",
    "<li>la premier étape c'est l'importation des bibliothèque utilisées ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ad85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import*\n",
    "from tqdm import *\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.feature import hog\n",
    "from BDM import*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8df018",
   "metadata": {},
   "source": [
    "les fichiers <strong>mnist_train.csv</strong> et <strong>mnist_train.csv</strong> contient des ligne de valeur composée de 785 valeur, la première valeur c'est une étiquette indique la classe de l’image, cette information est utilisé aussi pour faire l’apprentissage supervisée. Les valeurs de l'images commencent de la dixième valeur jusqu'à la fin de la ligne.tel que l'image est de taille 28 ×28 donc pour former l'image sous forme d’une matrice on doit redimensionner le vecteur ligne  en 28 lignes et 28 colonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700bd7f9",
   "metadata": {},
   "source": [
    "Pour le <strong>mnist_train.csv</strong> On va charger les 80 premières images de chaque classe ,le nombre total des images de l'entrainement  est 800.\n",
    "Pour <strong>mnist_test.csv</strong> On va charger les 20 premières images de chaque class ,le nombre total des images de test est 200."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf3f842",
   "metadata": {},
   "source": [
    "<li><strong>Charger les images depui les fichier csv: sous forme de datadrames</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38485ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour charger le fichier mnist_train.csv et mnist_test.csv\n",
    "Train_set_totale= pd.read_csv('mnist_train.csv')\n",
    "Test_set_totale= pd.read_csv('mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a948e3",
   "metadata": {},
   "source": [
    "La fonction pandas.read_csv permet de charger les images sous forme d'un objet pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92aa0c",
   "metadata": {},
   "source": [
    "<li><strong>Transformer les objet pandas (dataframes) en arrays</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281588e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformaer les fichers chargees  en tableau numpy\n",
    "Train_set_totale=np.array(Train_set_totale.iloc[::])\n",
    "Test_set_totale=np.array(Test_set_totale.iloc[::])\n",
    "print(\"shape du Train totale\",Train_set_totale.shape)\n",
    "print(\"shape du Test totale\",Test_set_totale.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ab9ba",
   "metadata": {},
   "source": [
    "Le morceau de code ci-dessus permet de convertir l'objet pandas en un array à l'aide de la méthode iloc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c818d",
   "metadata": {},
   "source": [
    "<li><strong>Charger la base de Train et la base de Test</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set =load_img(Train_set_totale,80,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d0b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set =load_img(Test_set_totale,20,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape du Train \",Train_set.shape)\n",
    "print(\"shape du Test \",Test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e5854",
   "metadata": {},
   "source": [
    "La fonction load_img(array_images,nombre_img_par_class,dim_img) permet de charger un nombre précis des premiers images de chaque classe dans un array donner.\n",
    "\n",
    "Cette fonction itère sur le tableau et à chaque ajouter d'une image il fait un redimensionnement de la ligne en 28×28pixel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f93ee47",
   "metadata": {},
   "source": [
    "la dimention de la base d'entrainement  et de test est respectivement  (28, 28, 800) et  (28, 28, 200) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae0a008",
   "metadata": {},
   "source": [
    "<li><strong>Affichage des images pour la verification:</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b45cf0",
   "metadata": {},
   "source": [
    "pour la base  Train_set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8577506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#il faut indiquer l'intervale des indecs des image a vusialiser \n",
    "#ex: incide de debut 0 ,incide de fin 10, \n",
    "#pour affiche les images des indices enter 0 et 10\n",
    "indice_debut=int(input(\"donner l'incide de debut [0,799]:\"))\n",
    "indice_fin=int(input(\"donner l'incide de fin [0,799]:\"))\n",
    "afficher_class(Train_set[:,:,indice_debut:indice_fin+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f8db8",
   "metadata": {},
   "source": [
    "pour la base Test_set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58f2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_debut=int(input(\"donner l'incide de debut [0,199]:\"))\n",
    "indice_fin=int(input(\"donner l'incide de fin [0,199]:\"))\n",
    "afficher_class(Test_set[:,:,indice_debut:indice_fin+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca990fa",
   "metadata": {},
   "source": [
    "<li><strong>Appliquer un prétraitement sur les deux base:</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f84838b",
   "metadata": {},
   "source": [
    "Le prétraitement des images avant l'indexation est une étape important, il permet de nettoyer et de préparer les images avant de les utiliser pour la recherche. Le prétraitement inclure des techniques telles que la réduction de bruit, redimensionnement, normalisation, etc.\n",
    "\n",
    "Dans notre cas on a appliqué 3 prétraitements:\n",
    "Le premier c'est une convolution de chaque image par le filtre suivant [3,3,4,4], ce filtre permet de flouter les images et atténuer les détailles .\n",
    "\n",
    "puis, on a appliqué un filtre médian pour la réduction du bruit et l’amélioration de la qualité des images .\n",
    "\n",
    "En dernier lieu une correction gamma est appliquer sur les images floutées.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set=pretraitement_1(Train_set)\n",
    "Test_set=pretraitement_1(Test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ffc36",
   "metadata": {},
   "source": [
    "Afin de voir l'amélioration que les images subit , vous prouver les afficher pour comparer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b8f0e",
   "metadata": {},
   "source": [
    "pour la base Train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_debut=int(input(\"donner l'incide de debut [0,799]:\"))\n",
    "indice_fin=int(input(\"donner l'incide de fin [0,799]:\"))\n",
    "afficher_class(Train_set[:,:,indice_debut:indice_fin+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a04f6e",
   "metadata": {},
   "source": [
    "pour la base Test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_debut=int(input(\"donner l'incide de debut [0,799]:\"))\n",
    "indice_fin=int(input(\"donner l'incide de fin [0,799]:\"))\n",
    "afficher_class(Test_set[:,:,indice_debut:indice_fin+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164b8e52",
   "metadata": {},
   "source": [
    "<li><strong>Générer la base des descripteur </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd349f7",
   "metadata": {},
   "source": [
    "les parametre qu'on a adobte pour le descripteur HOG sont:\n",
    "\n",
    "la taille des bloc:3×3 pixels , c'est une segmentation adapte avec la taille de l'image.\n",
    "\n",
    "nombre des orientation:4.\n",
    "\n",
    "nombre de bloc regroupe au mement de la normalisation:4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrpt_Train=discripteur_hog(Train_set)\n",
    "discrpt_Test=discripteur_hog(Test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f31e0",
   "metadata": {},
   "source": [
    "les dimention des base de descripteur  sont :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La dimention de la base des  descripteur Train \",discrpt_Train.shape)\n",
    "print(\"La dimention de la base des  descripteur Test \",discrpt_Test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8dc47",
   "metadata": {},
   "source": [
    "Ce qui montre que pour chaque image a été  représenter par une signature de dimension (1,2304)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOG,hog_img=hog(Train_set[:,:,90],orientations=4, pixels_per_cell=(3,3),cells_per_block=(4,4),visualize=True, feature_vector=True)\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(hog_img,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c414a39",
   "metadata": {},
   "source": [
    "Voici l'image de la class 1 après le calcule du gradient orienté "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477d674",
   "metadata": {},
   "source": [
    "Les images sont représentées par des vecteurs chacun de dimension (1,2304).\n",
    "\n",
    "La prochaine étape consiste à calculer la similarité entre les images à l'aide de la fonction de distance,la similarite est inversement proportionnele avec la distance,c’est-à-dire plus la distance est proche de 0 plus que les images sont similaires(appartient au même classe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06c1fc",
   "metadata": {},
   "source": [
    "<strong style=\"color:green\">Etude de la fonction distance</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7a3b2",
   "metadata": {},
   "source": [
    "En mathématiques, une distance est une application qui formalise l'idée intuitive de distance, c'est-à-dire la longueur qui sépare deux points de l'espace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c85d014",
   "metadata": {},
   "source": [
    "On appelle distance sur un ensemble E toute application d définie sur le produit E2 = E×E et à valeurs dans l'ensemble ℝ+ des réels positifs ou nuls,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851c5e1",
   "metadata": {},
   "source": [
    "<div  style=\"margin-left:350px;font-size:1.4em\"><strong>d:E×E-> ℝ+</strong></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289bfa1",
   "metadata": {},
   "source": [
    "la fonction de distance vérifie trois critères fondamentaux qui sont:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d7403",
   "metadata": {},
   "source": [
    " <ol>\n",
    "<li><strong>Symétrie :</strong> La distance entre deux points doit être la même, peu importe l'ordre dans lequel les points sont considérés.\n",
    "    \n",
    "    d(x,y)=d(y,x)\n",
    "\n",
    "</li>\n",
    "<li><strong>Identité des indiscernables :</strong> La distance entre deux points doit être nulle si et seulement si les points sont identiques.\n",
    "    \n",
    "    d(x,y)=0 <=> x=y\n",
    "</li>\n",
    "    <li><strong>L'inégalité triangulaire:</strong> quels que soient x, y et z de E on a  d(x,y) ≤ d(x,z)+d(z,y) \n",
    "    </li>\n",
    "</ol>\n",
    "(E,d) s'appelle alors un espace métrique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20238a23",
   "metadata": {},
   "source": [
    "Dans la  littérature, il y a plusieurs métriques  pour calculer la similarité entre deux descripteurs , tels que la distance de Manhattan,la distance euclidienne , la distance de Mahalanobis, la distance de Hamming, et bien d'autres encore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180e2c4",
   "metadata": {},
   "source": [
    "le choix de telle fonction de distance peut influencer sur la précision du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901291c",
   "metadata": {},
   "source": [
    "<img src=\"img/11.PNG\" style=\"height:200px;width:200px\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fd37d9",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><strong>Fig. 1-2:</strong> Distance de Manhattan (chemins rouge, jaune et bleu) contre distance euclidienne en vert.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0831a05f",
   "metadata": {},
   "source": [
    "On a adopté comme métrique la distance euclidienne pour des raisons de cout de calcule, de plus elle marche bien avec le descripteur choisi par rapport aux autre fonctions de distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13f602",
   "metadata": {},
   "source": [
    "Soit p et q deux vecteur d'un espace euclidien E , on définit la distance  euclidienne  entre les deux vecteur par la formule suivant:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc798ce",
   "metadata": {},
   "source": [
    "<img src=\"img/12.PNG\" style=\"height:80px;width:250px\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c42684",
   "metadata": {},
   "source": [
    "<li><strong>Générer la matrice de distance</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_distance=matrix_distance(discrpt_Train,discrpt_Test)\n",
    "matrice_distance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db648f46",
   "metadata": {},
   "source": [
    "Comme vous avez remarqué la matrice  de distance est de dimension (800,200), le nombre de lignes et le nombre de colonnes sont respectivement le nombre des images dans la base Train_set et le nombre des images dans la base Test_set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6880ce04",
   "metadata": {},
   "source": [
    "Par exemple la premier ligne de la matrice de distance, est l'ensemble des distances entre  la première image de la base Train_set avec toutes les images de la base Test_set ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb6ef20",
   "metadata": {},
   "source": [
    "<li><strong>Générer la matrice matrice des indices</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd444b8c",
   "metadata": {},
   "source": [
    "Cette étape c'est pour la classification pour retourner les images les plus pertinantes en se basat sur L’algorithme  le plus proche voisin <strong>(KNN for k-nearest neighbors.) </strong> ,c’ est parmi les plus simples des algorithmes de classification , le principe est de tri les résultats selon la distance et retourner un nombre K des plus proche voisin,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ef537",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_indice=index_similarite(matrice_distance)\n",
    "matrice_indice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411436dc",
   "metadata": {},
   "source": [
    "Noter bien que la matrice des indices a toujours la même dimension que la matrice de distances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a192c811",
   "metadata": {},
   "source": [
    "<li><strong>Générer la matrice matrice binaire</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1677d7",
   "metadata": {},
   "source": [
    "Une étape très importante dans la retour de pertinence c'est la génération de la matrice binaire (ou booléen)\n",
    ", comme son l'indique c'est une matrice composer par les deux états 0 et 1. Dans une ligne i et une colonne j, on va donner l'information sur l'image retourner par le système est ce qu'elle est pertinente ou non. \n",
    "Si on trouve 1 indique l'image retourner par le système est pertinent (apparier à la même class des chiffres) sinon l'images retourner n'est pas pertinente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_binair=matrix_boolean(matrice_indice,80,20)\n",
    "matrice_binair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afafc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_binair[0,:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16ee8f",
   "metadata": {},
   "source": [
    "Le morceau de code ci-dessus, indique que parmi les 15 premiers images retourner, on a une seul qui n'est pas pertinente c'est l’image avant la dernier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d683e0d",
   "metadata": {},
   "source": [
    "<h2 class=\"ch\" style=\"font-weight: bold;font-family:serif;font-size:2em\">Chapitre 3: <span>Evaluation et mesure de performance</span></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d301a83",
   "metadata": {},
   "source": [
    "L'évaluation d'un système de recherche d'information est importante pour plusieurs raisons.Elle permet de mesurer la plausibilité  et l'efficacité du système en termes de précision, de rappel et d'autres mesures de performance. Cela permet  de comprendre les forces et les faiblesses du système .\n",
    "\n",
    "En outre, l'évaluation est importante pour comparer différents systèmes de recherche d'information entre eux et pour évaluer leur adéquation pour différents cas d'utilisation. Cela peut aider à prendre des décisions éclairées sur le choix d'un système de recherche d'information pour répondre à des  besoins ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed244182",
   "metadata": {},
   "source": [
    "Dans ce chapitre en va aborder deux mesures qui sont très utiliser, sont la précision moyenne (Mean Average Precision) et la courbe CMC (Cumulative Match Characteristic).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54550ca3",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:serif\">III.1)Rappel et précision</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e155a5",
   "metadata": {},
   "source": [
    "Rappel et précision sont deux mesure qu'on peut les calculer à partir de la matrice  de confision.\n",
    "\n",
    "La matrice de confusion montre le nombre de prédictions correctes et incorrectes pour chaque interrogation effectuer , en les comparant aux valeurs réelles. Les éléments principaux de la matrice de confusion comprennent les vrais positifs, les faux positifs, les vrais négatifs et les faux négatifs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e22457",
   "metadata": {},
   "source": [
    "<img src=\"img/18.PNG\" style=\"height:200px;width:350px\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5030f",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><strong>Fig. 1-3:</strong> La matrice de confusion </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31f503d",
   "metadata": {},
   "source": [
    "La matrice de confusion donne l'information sur les documents pertinents et non pertinente attribuer à une class par le système de recherche d'information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853623fe",
   "metadata": {},
   "source": [
    "<img src=\"img/15.PNG\" style=\"height:400px;width:350px\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529e1173",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><strong>Fig. 1-4:</strong> La retour de pertinence </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d143fe",
   "metadata": {},
   "source": [
    "Dans un ordre i donnée  ,la précision est le nombre des images pertinents retrouvés rapporté au nombre des images  total proposé pour une requête donnée.\n",
    "\n",
    "Le rappel est défini par le nombre des images pertinents retrouvés au regard du nombre des images pertinents que possède la base de données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab3c2b",
   "metadata": {},
   "source": [
    "<img src=\"img/17.PNG\" style=\"height:120px;width:280px\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed59a9",
   "metadata": {},
   "source": [
    "À l'aide de la figure 1-4 on peut modéliser les deux formules par:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04346241",
   "metadata": {},
   "source": [
    "<img src=\"img/16.PNG\" style=\"height:150px;width:300px\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f22f490",
   "metadata": {},
   "source": [
    "D'une autre manier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d3f50",
   "metadata": {},
   "source": [
    "<img src=\"img/13.PNG\" style=\"height:80px;width:550px\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4dee2",
   "metadata": {},
   "source": [
    "<img src=\"img/14.PNG\" style=\"height:80px;width:550px\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145bf21",
   "metadata": {},
   "source": [
    "Pour  nôtre cas, on va calculer la précision pour chaque rang i (de 0 à 199). Et puis une moyenne de précision ça sera calculer  en prenant compte que les range qu'ont comme dernier image est pertinent (c'est à dire égal à 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca0ba93",
   "metadata": {},
   "source": [
    "Après cette étape , on a une liste des valeurs de moyenne de langueur inferieur ou égale 200. Encore une fois une moyenne ça sera calculer sur les précision moyenne trouver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a8d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_reccal,matrix_precision,matrix_moy_pre=evaluer_modele(matrice_binair)\n",
    "moyenne_prec=moyenne_precision(matrix_moy_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"la precision moyenne:\",moyenne_prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d057d8",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family:serif\">III.2)La courbe CMC</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1b19b",
   "metadata": {},
   "source": [
    "La Cumulative Match Characteristic (CMC) est une mesure d'évaluation de la performance des systèmes de recherche d'information. Elle représente la proportion de requêtes  correctement identifiées parmi un nombre croissant de candidats classés par ordre de similarité avec la requête."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05f9d8",
   "metadata": {},
   "source": [
    "En d'autres termes, la CMC permet de visualiser la performance d'un système de reconnaissance faciale à travers un graphique qui montre le taux de reconnaissance pour les N meilleures correspondances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534ec522",
   "metadata": {},
   "source": [
    "La CMC est largement utilisée pour évaluer les performances des systèmes de recherche d'information (sur tout pour la reconnaissance faciale ) . Elle permet de comparer la performance de différents systèmes en fonction de leur capacité à identifier correctement les classes dans une base de données de référence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic=np.zeros((800))\n",
    "ir=np.zeros((200))\n",
    "pas=80\n",
    "for i in range(1,10):\n",
    "    ic[pas:pas+80]=i\n",
    "    pas+=80\n",
    "pas=20\n",
    "for i in range(1,10):\n",
    "    ir[pas:pas+20]=i\n",
    "    pas+=20\n",
    "courbe_CMC=CMC(matrice_distance,ic,ir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c02ae",
   "metadata": {},
   "source": [
    "**remarque:** si vous vouler re-exécuter cette cellue il faut restarter le kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(courbe_CMC)\n",
    "plt.xlabel(\"L'ordre\")\n",
    "plt.ylabel(\"Le taux de reconnaissance\")\n",
    "plt.title(\"la courbe CMC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2c42e",
   "metadata": {},
   "source": [
    "<h2 class=\"ch\" style=\"font-weight: bold;font-family:serif;font-size:2em\">Chapitre 4: <span>Résumer </span></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f5ded6",
   "metadata": {},
   "source": [
    "L’indexation sur la base de MNIST ce n’est pas facile à réaliser pour plusieurs raisons.\n",
    " Le même chiffre peut écrire par différents manières   d'une personne à l'autre ce qui est facile à l'identifier pour nous comme des êtres humains, mais ça pose un problème pour les systèmes de recherche d’information. En deuxième lieu, la rotation des chiffres pose  un autre problème puisque le descripteur utilisée dans notre système  n'est pas flexible avec les opérations géométriques des objets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a80ac",
   "metadata": {},
   "source": [
    "<li><strong>Travaille supplémentaire: </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f21e9",
   "metadata": {},
   "source": [
    "On propose dans cette dernière partie de vous donner la possibilité de lancer des requêtes   On a choisi parmi les 10 000 images de test de MNIST 100 comme des requêtes ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour charger le fichier mnist_train.csv et mnist_test.csv\n",
    "Test= pd.read_csv('mnist_test.csv')\n",
    "Test=np.array(Test.iloc[::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_test(Test):\n",
    "    test=np.zeros((28,28,100))\n",
    "    for i in range(100):\n",
    "        test[:,:,i]=np.reshape(Test[9999-i,1:],(28,28))\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=images_test(Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9124dc06",
   "metadata": {},
   "source": [
    "les images requêtes que vous pouvez lancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec38be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,25))\n",
    "for i in tqdm(range(100)):\n",
    "    plt.subplot(10,10,i+1)\n",
    "    plt.title(i+1)\n",
    "    plt.imshow(test[:,:,i],'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d185f9",
   "metadata": {},
   "source": [
    "Donner l'indice de l'image requête (de 1 à 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cd2d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=int(input())\n",
    "requet=test[:,:,index-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e403e3",
   "metadata": {},
   "source": [
    "on va appliquer le même prétraitement  sur la requête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0fc9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "requet=scipy.ndimage.filters.convolve1d(requet, weights=[3,3,4,4],axis=-1)\n",
    "requet = scipy.ndimage.median_filter(requet, 3)\n",
    "gamma = 0.5\n",
    "requet = np.power(  requet, gamma) \n",
    "plt.imshow(requet,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8625f94b",
   "metadata": {},
   "source": [
    "Extraire les descripteur HOG de l'image requête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_requet=hog(requet,orientations=4, pixels_per_cell=(3,3),cells_per_block=(4,4),visualize=False, feature_vector=True)\n",
    "desc_requet= desc_requet/np.linalg.norm( desc_requet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3614ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecteur_distance=np.zeros(800)\n",
    "for i in range(800):\n",
    "    vecteur_distance[i]=Euclidien(desc_requet,discrpt_Train[i])\n",
    "vecteur_indice=np.argsort(vecteur_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54220219",
   "metadata": {},
   "source": [
    "le choix de nombre d'image à retourner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a0d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_images=int(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d8cb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,25))\n",
    "for i in vecteur_indice[:nombre_images]:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(Train_set[:,:,i],'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73efd9",
   "metadata": {},
   "source": [
    "**-------------------------------------------------------------------------------------------Fin-------------------------------------------------------------------------------------------------------------------**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
